### title is shown as status in motd
### status is one of: success, warning, danger

# ---
# status: success
# author: HPC Team Freiburg
# date: 2023-12-20
# title: 'NEMO: normal operation'
# text: >
#   Security update Christmas applied (CentOS 7.9, Rev. 39).
#   <br />
#   See update log for timestamps <code>/opt/bwhpc/os-revisions/security_update_2023-12</code>.
# ---

---
status: warning
author: HPC Team Freiburg
date: 2024-01-30
title: Security Update Christmas 2023
text: >
  Starting 01.02., the operating system of NEMO's worker, vis, workflow and login nodes will be updated.
  <br />
  The nodes will be rebooted at:
  <br />
  login1   : 2024-02-01 18:00 CET (scheduled)
  <br />
  login2   : 2024-02-02 08:00 CET (scheduled)
  <br />
  vis      : 2024-02-01 18:00 CET (scheduled)
  <br />
  workflow : 2024-02-01 18:00 CET (scheduled)
  <br />
  worker   : 2024-02-01 starting 14:00 CET (scheduled)
  <br />
  Worker nodes automatically reboot after the last job finishes, see
  /opt/bwhpc/os-revisions/security_update_2024-02
  for reboot timestamps (created when update starts).
---

# ---
# status: success
# author: HPC Team Freiburg
# title: 'NEMO: normal operation'
# text: >
#   Reboot of login1 on 18.05. at 18:00 CEST -> successful.
#   <br />
#   CVMFS mount on login1 works again.
# ---

# ---
# status: success
# author: HPC Team Freiburg
# date: 2021-07-26
# title: 'NEMO: normal operation'
# text: >
#   Important security update applied (CentOS 7.9, Rev. 9), fixes CVE-2021-33909.
#   <br />
#   For more info see Red Hat Security Bulletin: https://access.redhat.com/security/vulnerabilities/RHSB-2021-006.
# ---

# ---
# status: success
# author: HPC Team Freiburg
# date: 2022-03-03
# title: 'NEMO: normal operation'
# text: >
#   The maintenance of the uninterruptible power supply was successfully completed.
#   <br />
#   In addition, the March security update was applied (CentOS 7.9, Rev. 17).
#   <br />
#   See update log for timestamps <code>/opt/bwhpc/os-revisions/security_update_2022-03</code>.
# ---

# ---
# status: success
# author: HPC Team Freiburg
# date: 2022-11-21
# title: 'NEMO: normal operation'
# text: >
#   Security update August applied (CentOS 7.9, Rev. 37).
#   <br />
#   We will introduce the 2FA login in 2023 (see news).
# ---

# ---
# status: success
# author: HPC Team Freiburg
# date: 2022-08-08
# title: 'NEMO: normal operation'
# text: >
#   Maintenance has been completed.
#   The Omni-Path uplinks have been repaired.
#   Currently, about 80% of the NEMO cluster is online.
#   <br />
#   UPDATE 09.09.2022: About 90% of the NEMO cluster is online.
#   <br />
#   In addition, the August security update was applied (CentOS 7.9, Rev. 22).
# ---

# ---
# status: warning
# author: HPC Team Freiburg
# date: 2022-07-05
# title: 'NEMO: normal operation'
# text: >
#   Reboot of login2 on 06.07. at 08:00 CEST.
#   <br />
#   login2 must be restarted after the security update.
# ---

# ---
# status: warning
# author: HPC Team Freiburg
# date: 2021-11-16
# title: Login to NEMO disrupted
# text: >
#   Login to the NEMO cluster is currently disrupted outside the university.
# ---

# ---
# status: warning
# author: HPC Team Freiburg
# date: 2021-09-16
# title: Sporadic problems witch secondary groups
# text: >
#   Sporadic dropouts in communication with the application page for computing projects.
#   The project name "bwYYzNNNN" is used for secondary groups in NEMO.
#   Problems which can occur:
#   <br />
#   * Login to NEMO fails with a notice to log in to the registration server.
#   <br />
#   * The registration server indicates that a requirement for the service NEMO is missing.
#   <br />
#   * Access to workspaces where the secondary group is used to allow access (ACL, setfacl).
#   <br />
#   We are working on the problem.
# ---

# ---
# status: danger
# author: HPC Team Freiburg
# date: 2022-08-02
# title: Scheduled High Performance Network Maintenance 08.08.2022
# text: >
#   We need to reboot all Omni-Path switches and replace some cables.
#   Since the workspaces and MPI jobs depend on OPA, the entire cluster will be shut down for a few hours.
#   <br />
#   <br />
#   <strong>Date: 08.08.2022 8:00 - 18:00 CEST</strong>
#   <br />
#   <br />
#   The entire NEMO cluster will be shut down.
#   No computations are possible during maintenance, so submit all jobs on time.
#   Note that only jobs whose walltime fits within the time window until maintenance can be started.
#   Jobs that cannot be started will be processed afterwards.
#   However, if problems occur, the queue may need to be emptied.
#   During maintenance, the operating system of the cluster is updated.
# ---

# ---
# status: danger
# author: HPC Team Freiburg
# date: 2022-02-22
# title: Scheduled Power Maintenance 03.03.2022
# text: >
#   Inspection of the data center power supply.
#   <br />
#   <br />
#   <strong>Date: 03.03.2022 6:00 - 18:00 CET</strong>
#   <br />
#   <br />
#   The complete NEMO cluster will be shut down.
#   No computing is possible during the maintenance, so submit all jobs in time.
#   Note that only jobs whose walltime fits into the time window until maintenance can start.
#   Jobs that cannot start will only be processed afterwards.
#   However, in the event of problems, the queue may have to be emptied.
#   During maintenance the operating system of the cluster is updated.
# ---

# ---
# status: warning
# author: HPC Team Freiburg
# date: 2023-05-11
# title: NEMO Network Problems
# text: >
#   A damaged network switch caused 88 nodes to fail today.
#   The computing nodes were rebooted and the running jobs on these nodes were terminated.
#   The problem has been fixed in the meantime.
#   <br />
#   UPDATE: 06/02/2023:
#   Another damaged switch caused 44 nodes to crash today.
#   The problem has been fixed.
#   <br />
#   After so many years this is to be expected,
#   so in the next few weeks we will try to check the remaining switches in the cluster and replace them in advance.
# ---

# ---
# status: warning
# author: HPC Team Freiburg
# date: 2021-07-08
# title: NEMO Power Outage
# text: >
#   There has been a power outage in the morning of the 08.07.2021 (shortly after 7 o'clock).
#   All worker nodes rebooted and all running jobs were killed instantly.
#   <br />
#   The cluster is working normally again.
# ---

# ---
# status: danger
# author: HPC Team Freiburg
# date: 2021-06-28
# title: Maintenance ...
# text: >
#   Start : 2021-07-01 08:00
#   <br />
#   End   : 2021-07-01 18:00
# ---
